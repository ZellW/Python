{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTMDkffWSky-"
   },
   "source": [
    "\n",
    "# Objective\n",
    "\n",
    "The objective of notebook is to build a model to automatically predict tags for a given a StackExchange question by using the text of the question in PyTorch.\n",
    "![alt text](https://cdn.sstatic.net/Sites/stackoverflow/company/img/logos/se/se-logo.svg?v=d29f0785ebb7)\n",
    "\n",
    "__Dataset Specs__: Over 85,000 questions and over 1300 unique tags\n",
    "\n",
    "[Download Link](https://www.kaggle.com/stackoverflow/statsquestions#Questions.csv)\n",
    "\n",
    "\n",
    "# Steps To Follow\n",
    "\n",
    "\n",
    "1. Load Data and Import Libraries\n",
    "\n",
    "2. Dataset Preparation\n",
    "\n",
    "      2.1 Merge Tags with Questions\n",
    "\n",
    "      2.2 Filter Questions with respect to Top-10 Tags\n",
    "      \n",
    "3. Text Preprocessing\n",
    "\n",
    "      3.1 Text Cleaning\n",
    "\n",
    "      3.2 Text Representation\n",
    "\n",
    "4. Model Building\n",
    "\n",
    "      4.1 Model Architecture\n",
    "\n",
    "      4.2 Model Training\n",
    "\n",
    "5. Model Evaluation\n",
    "\n",
    "      5.1 Check Performance\n",
    "\n",
    "      5.2 Show Inference\n",
    "\n",
    "6. Model Building for LSTM\n",
    "\n",
    "7. Model Evaluation for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48YGFqrAy6zf"
   },
   "source": [
    "# 1. Load Data and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67975,
     "status": "ok",
     "timestamp": 1587056532326,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "bJvSO7bDONu4",
    "outputId": "bcd922c8-5b1b-4d32-85d6-f7f18e05905f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17012,
     "status": "ok",
     "timestamp": 1587056544183,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "aZiyIx06RTdD",
    "outputId": "9c52fbfd-fbc6-4e78-fe62-dbcf5cd84181"
   },
   "outputs": [],
   "source": [
    "# extract data from the ZIP file\n",
    "# !unzip '/content/drive/My Drive/statsquestions.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fM2S4yCsR7i6"
   },
   "outputs": [],
   "source": [
    "#string matching\n",
    "import re \n",
    "\n",
    "#reading files\n",
    "import pandas as pd\n",
    "## change display width of pandas dataframe\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "#array processing\n",
    "import numpy as np\n",
    "\n",
    "#handling html data\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "#for metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "#for seed\n",
    "import random\n",
    "\n",
    "# to one hot encode labels\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "#defining tensors\n",
    "import torch\n",
    "\n",
    "#layers\n",
    "from torch import nn\n",
    "\n",
    "#layers and wrappers\n",
    "from torch.nn import Sequential, Linear,  ReLU, Sigmoid, Dropout, BCELoss, Embedding, RNN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling text data\n",
    "# conda install -c pytorch torchtext\n",
    "from torchtext import data  #using torch rather than keras here for preprocessing\n",
    "\n",
    "# https://stackoverflow.com/questions/63539809/torchtext-0-7-shows-field-is-being-deprecated-what-is-the-alternative\n",
    "# import torchtext.legacy as torchtext # unable to conda isntall\n",
    "\n",
    "# https://github.com/pytorch/text/tree/master/torchtext/legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JD8BvEEFR_40"
   },
   "outputs": [],
   "source": [
    "# load the stackoverflow questions dataset\n",
    "# questions_df = pd.read_csv('Questions.csv',encoding='latin-1')\n",
    "questions_df = pd.read_csv('../../../../../LargeData/Analytics_Vidhya/StackOverflow_tagging/Questions.csv',encoding='latin-1')\n",
    "\n",
    "# load the tags dataset\n",
    "tags_df = pd.read_csv('../../../../../LargeData/Analytics_Vidhya/StackOverflow_tagging/Tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5106,
     "status": "ok",
     "timestamp": 1587057084817,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "mE88kY9WR_-n",
    "outputId": "94da7aa0-0379-4966-d1f6-5307c695b8ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-07-19T19:14:44Z</td>\n",
       "      <td>272</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2010-07-19T19:24:36Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2010-07-19T19:25:39Z</td>\n",
       "      <td>208</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain English</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010-07-19T19:28:44Z</td>\n",
       "      <td>138</td>\n",
       "      <td>What is the meaning of p values and t values in statistical tests?</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2010-07-19T19:31:47Z</td>\n",
       "      <td>58</td>\n",
       "      <td>Examples for teaching: Correlation does not mean causation</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId          CreationDate  Score  \\\n",
       "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
       "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
       "2  22         66.0  2010-07-19T19:25:39Z    208   \n",
       "3  31         13.0  2010-07-19T19:28:44Z    138   \n",
       "4  36          8.0  2010-07-19T19:31:47Z     58   \n",
       "\n",
       "                                                                Title  \\\n",
       "0                  The Two Cultures: statistics vs. machine learning?   \n",
       "1                                      Forecasting demographic census   \n",
       "2                 Bayesian and frequentist reasoning in plain English   \n",
       "3  What is the meaning of p values and t values in statistical tests?   \n",
       "4          Examples for teaching: Correlation does not mean causation   \n",
       "\n",
       "                                                                                                                                                                                                      Body  \n",
       "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...  \n",
       "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...  \n",
       "2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n  \n",
       "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....  \n",
       "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Glance at the first 5 rows\n",
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4769,
     "status": "ok",
     "timestamp": 1587057084818,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "qxvK_9YFG2M1",
    "outputId": "d4b03840-5bf7-49ae-9df9-87844587890d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85085, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the dataset\n",
    "questions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4491,
     "status": "ok",
     "timestamp": 1587057084818,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "o7wSglDJSGWf",
    "outputId": "17539cf5-237b-4276-f5bf-391dc54e9b62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>elicitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>normality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id            Tag\n",
       "0   1       bayesian\n",
       "1   1          prior\n",
       "2   1    elicitation\n",
       "3   2  distributions\n",
       "4   2      normality"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a glance at first 5 rows\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4307,
     "status": "ok",
     "timestamp": 1587057084820,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "Xz1-htTsSGM8",
    "outputId": "e211ec41-127f-4eb6-f5ba-2ed0fe39a42f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1315"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of unique tags\n",
    "len(tags_df['Tag'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nQjFYQtTNH6"
   },
   "source": [
    "# 2. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--FBzpS7y2t7"
   },
   "source": [
    "## 2.1 Merge Tags with Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKoRHljISb83"
   },
   "outputs": [],
   "source": [
    "# remove \"-\" from the tags\n",
    "tags_df['Tag'] = tags_df['Tag'].apply(lambda x:re.sub(\"-\",\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6362,
     "status": "ok",
     "timestamp": 1587057088087,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "mWQyeoa4ScDz",
    "outputId": "3e177c0d-3c84-4079-f2bf-de49d988f04c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[bayesian, prior, elicitation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[distributions, normality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[software, open source]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[distributions, statistical significance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[machine learning]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                       tags\n",
       "0   1             [bayesian, prior, elicitation]\n",
       "1   2                 [distributions, normality]\n",
       "2   3                    [software, open source]\n",
       "3   4  [distributions, statistical significance]\n",
       "4   6                         [machine learning]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group tags Id wise\n",
    "tags_df = tags_df.groupby('Id').apply(lambda x:x['Tag'].values).reset_index(name='tags')\n",
    "tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EB8sYYOrScCC"
   },
   "outputs": [],
   "source": [
    "# merge tags and questions\n",
    "df = pd.merge(questions_df,tags_df,how='inner',on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pD7UD9yNSmk1"
   },
   "outputs": [],
   "source": [
    "# fetch required columns\n",
    "df = df[['Id','Body','tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5495,
     "status": "ok",
     "timestamp": 1587057088090,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "zZEEr2B5eosb",
    "outputId": "b39aa80e-d8e0-4638-9ab6-d8a720a94588"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Body</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
       "      <td>[machine learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
       "      <td>[forecasting, population, census]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
       "      <td>[bayesian, frequentist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
       "      <td>[hypothesis testing, t test, p value, interpretation, intuition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
       "      <td>[correlation, teaching]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  \\\n",
       "0   6   \n",
       "1  21   \n",
       "2  22   \n",
       "3  31   \n",
       "4  36   \n",
       "\n",
       "                                                                                                                                                                                                      Body  \\\n",
       "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...   \n",
       "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...   \n",
       "2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n   \n",
       "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....   \n",
       "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...   \n",
       "\n",
       "                                                               tags  \n",
       "0                                                [machine learning]  \n",
       "1                                 [forecasting, population, census]  \n",
       "2                                           [bayesian, frequentist]  \n",
       "3  [hypothesis testing, t test, p value, interpretation, intuition]  \n",
       "4                                           [correlation, teaching]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5249,
     "status": "ok",
     "timestamp": 1587057088092,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "J28FYn8xSmqM",
    "outputId": "5b4feef7-644d-4a60-b758-47d8d43bd6fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85085, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1ZvB-t9TYKh"
   },
   "source": [
    "## 2.2 Filter Questions with respect to Top-10 Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n9XRjQ_wSmvh"
   },
   "outputs": [],
   "source": [
    "# check occurence of each tag\n",
    "freq={} # cretae dictionary\n",
    "for i in df['tags']:\n",
    "  for j in i:\n",
    "    if j in freq.keys():\n",
    "      freq[j] = freq[j] + 1\n",
    "    else:\n",
    "      freq[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSVPSJnCSvUt"
   },
   "outputs": [],
   "source": [
    "# sort the dictionary in descending order\n",
    "freq = dict(sorted(freq.items(), key=lambda x:x[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4159,
     "status": "ok",
     "timestamp": 1587057088095,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "PxDCpuGFSvhH",
    "outputId": "209a157d-b77b-45f3-ea6e-5fae88b0c8c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r', 'regression', 'machine learning', 'time series', 'probability', 'hypothesis testing', 'self study', 'distributions', 'logistic', 'classification']\n"
     ]
    }
   ],
   "source": [
    "# Top 10 most frequent tags\n",
    "common_tags = list(freq.keys())[:10]\n",
    "print(common_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPC21Z5aTkB8"
   },
   "source": [
    "We will use only those questions/queries that are associated with the top 10 tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNksVjF6SvqS"
   },
   "outputs": [],
   "source": [
    "#finding queries associated with common tags\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for i in range(len(df['tags'])):  \n",
    "\n",
    "  temp=[]\n",
    "  for j in df['tags'][i]:\n",
    "    if j in common_tags:\n",
    "      temp.append(j)\n",
    "  \n",
    "  #if common tags are more than 1\n",
    "  if(len(temp)>1):\n",
    "    x.append(df['Body'][i])\n",
    "    y.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5101,
     "status": "ok",
     "timestamp": 1587057090427,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "Ck6w3DsfS82D",
    "outputId": "5d0ad330-9543-44d4-ab75-44909807bba3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11106"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of questions left\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4773,
     "status": "ok",
     "timestamp": 1587057090428,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "2tLZqaHQ-4Bz",
    "outputId": "20b776e0-d934-41b7-90d2-bbc6207e842e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r', 'time series'],\n",
       " ['regression', 'distributions'],\n",
       " ['distributions', 'probability', 'hypothesis testing'],\n",
       " ['hypothesis testing', 'self study'],\n",
       " ['r', 'regression', 'time series']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first 5 tags\n",
    "y[:5]\n",
    "# creates lsits within a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfTeISu8A3KT"
   },
   "outputs": [],
   "source": [
    "#combining the labels by space\n",
    "y = [ \",\".join([str(j) for j in i ]) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3967,
     "status": "ok",
     "timestamp": 1587057090430,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "LnceeB6B_Tbd",
    "outputId": "d180f8f0-ae67-4caa-d1ff-4c0e617ec459"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r,time series',\n",
       " 'regression,distributions',\n",
       " 'distributions,probability,hypothesis testing',\n",
       " 'hypothesis testing,self study',\n",
       " 'r,regression,time series']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels after converting to string\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYblHXWVgt_S"
   },
   "outputs": [],
   "source": [
    "#save to dataframe\n",
    "dframe = pd.DataFrame({'query':x,'tags':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2871,
     "status": "ok",
     "timestamp": 1587057090431,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "fGUumAqqBpDa",
    "outputId": "7b0cb857-43ae-4cf5-cd9d-fe8450f84e06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I recently started working for a tuberculosis clinic.  We meet periodically to discuss the number of TB cases we're currently treating, the number of tests administered, etc.  I'd like to start...</td>\n",
       "      <td>r,time series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;Am I looking for a better behaved distribution for the independent variable in question, or to reduce the effect of outliers, or something else?&lt;/p&gt;\\n</td>\n",
       "      <td>regression,distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;There are many ways to measure how similar two probability distributions are.  Among methods which are popular (in different circles) are:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;&lt;p&gt;the Kolmogorov distance: the sup-d...</td>\n",
       "      <td>distributions,probability,hypothesis testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;A Lab has been asked to evaluate the claim that drinking water in a\\n  local restaurant has a lead concentration of 6 parts per billion\\n  (ppb). Repeated measurements follow a ...</td>\n",
       "      <td>hypothesis testing,self study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;How would we measure the predictive power of predictors in time series models. For e.g. in linear regression we have the magnitude and direction of the regression co-efficients and their p-valu...</td>\n",
       "      <td>r,regression,time series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                     query  \\\n",
       "0  <p>I recently started working for a tuberculosis clinic.  We meet periodically to discuss the number of TB cases we're currently treating, the number of tests administered, etc.  I'd like to start...   \n",
       "1                                                <p>Am I looking for a better behaved distribution for the independent variable in question, or to reduce the effect of outliers, or something else?</p>\\n   \n",
       "2  <p>There are many ways to measure how similar two probability distributions are.  Among methods which are popular (in different circles) are:</p>\\n\\n<ol>\\n<li><p>the Kolmogorov distance: the sup-d...   \n",
       "3  <blockquote>\\n  <p>A Lab has been asked to evaluate the claim that drinking water in a\\n  local restaurant has a lead concentration of 6 parts per billion\\n  (ppb). Repeated measurements follow a ...   \n",
       "4  <p>How would we measure the predictive power of predictors in time series models. For e.g. in linear regression we have the magnitude and direction of the regression co-efficients and their p-valu...   \n",
       "\n",
       "                                           tags  \n",
       "0                                 r,time series  \n",
       "1                      regression,distributions  \n",
       "2  distributions,probability,hypothesis testing  \n",
       "3                 hypothesis testing,self study  \n",
       "4                      r,regression,time series  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first 5 rows\n",
    "dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27-gnDPi60yg"
   },
   "outputs": [],
   "source": [
    "#save to csv\n",
    "dframe.to_csv('../../../../../LargeData/Analytics_Vidhya/StackOverflow_tagging/stack.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5E3gvtJ0_eC"
   },
   "source": [
    "# 3. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Je87HHtQA6bO"
   },
   "source": [
    "*Much of the infomartion below is legacy.  New version on torchtext changes muost of this.*\n",
    "https://github.com/pytorch/text/tree/master/torchtext/legacy\n",
    "\n",
    "Now, we will see the one of the most important library in PyTorch for handling text data - TorchText \n",
    "\n",
    "**TorchText** is a Natural Language Processing (NLP) library in PyTorch. This library contains the scripts for preprocessing text and data sources of few popular NLP datasets to test out the scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLmFzuLDCH0d"
   },
   "source": [
    "TorchText understands and operates on text data in terms of Field objects, and then Field objects are used to define the steps for text preprocessing\n",
    "\n",
    "There are 2 different types of field objects – **Field** and **LabelField**. \n",
    "\n",
    "* **Field**: Field object is used to specify preprocessing steps for each column in the dataset.\n",
    "\n",
    "* **LabelField**: LabelField object is a special case of Field object which is used only for the preprocessing of label column. \n",
    "\n",
    "Before we use Field, let us look at the different parameters of Field and what are they used for.\n",
    "\n",
    "**Parameters of Field**:\n",
    "\n",
    "* **Tokenize**: It specifies the way of tokenizing the sentence i.e. converting sentence to words. By default, it tokenizes with respect to spaces\n",
    "\n",
    "    * *Note*: It can be replaced by the preprocessing function as well.\n",
    "\n",
    "* **Lower**: It converts text to lowercase\n",
    "\n",
    "* **batch_first**: The first dimension of input and output is always batch size\n",
    "\n",
    "* **fix_length**: Maximum length of a sentence\n",
    "\n",
    "* **unk_token**: The string token used to represent OOV words. By default, this value is \"UNK\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IM2i7pJ-1RLm"
   },
   "source": [
    "## 3.1 Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruV5khtmAiDU"
   },
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "\n",
    "  text = BeautifulSoup(text).get_text()\n",
    "  \n",
    "  # fetch alphabetic characters\n",
    "  text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "\n",
    "  # convert text to lower case\n",
    "  text = text.lower()\n",
    "\n",
    "  # split text into tokens to remove whitespaces\n",
    "  tokens = text.split()\n",
    "  \n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SW0eN1UnrchO"
   },
   "outputs": [],
   "source": [
    "#define field object for query\n",
    "max_len = 100\n",
    "TEXT = torchtext.data.Field(tokenize=cleaner, batch_first=True, fix_length=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9PfZ04R8NkK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czwea\\anaconda3\\envs\\deep\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#define field object for label\n",
    "LABEL = data.LabelField(batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlM-zyeSEkEi"
   },
   "source": [
    "Next we are going to create a list of tuples where first value in every tuple contains a column name and second value is a field object. Furthermore we will arrange each tuple in the order of the columns of csv.\n",
    "\n",
    "Let us read only required columns – query and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFoE3QDb8NfI"
   },
   "outputs": [],
   "source": [
    "#define a list of tuple with field objects\n",
    "fields = [('query',TEXT),('tags', LABEL)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtZKZJZVEvCS"
   },
   "source": [
    "Now, we will load the custom dataset by defining the list of tuples. For this we use TabularDataset class\n",
    "\n",
    "**Parameters of TabularDataset**:\n",
    "\n",
    "* **path**: set the path of dataset\n",
    "\n",
    "* **format**: provide extension of file. \n",
    "    * **Note**: There are a limited number of extensions accepted by TorchText. Read the docs for more details\n",
    "\n",
    "* **fields**: give tuple of user defined fields which data would have\n",
    "\n",
    "* **skip_header**: boolean value; if set to true - ignores the first line of the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpOti-uNS8z_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czwea\\anaconda3\\envs\\deep\\lib\\site-packages\\torchtext\\data\\example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "C:\\Users\\czwea\\anaconda3\\envs\\deep\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#reading the dataset\n",
    "training_data = data.TabularDataset(\n",
    "    path = '../../../../../LargeData/Analytics_Vidhya/StackOverflow_tagging/stack.csv', \n",
    "    format = 'csv', fields = fields, skip_header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nDXopkVgS9vy"
   },
   "source": [
    "Let see whether we can see examples of training data or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6662,
     "status": "ok",
     "timestamp": 1587057100624,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "w_U5N4OsS_ZI",
    "outputId": "1567d936-6b95-494c-cbc6-ff90a98543bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.dataset.TabularDataset object at 0x00000294271E6FA0>\n"
     ]
    }
   ],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hvxo_fyTKPE"
   },
   "source": [
    "Now, we will see how to print the examples of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5740,
     "status": "ok",
     "timestamp": 1587057100625,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "t_imud4VBcGP",
    "outputId": "72ebf69d-1ad3-408f-9d92-bcf6dbc1cfc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': ['i', 'recently', 'started', 'working', 'for', 'a', 'tuberculosis', 'clinic', 'we', 'meet', 'periodically', 'to', 'discuss', 'the', 'number', 'of', 'tb', 'cases', 'we', 're', 'currently', 'treating', 'the', 'number', 'of', 'tests', 'administered', 'etc', 'i', 'd', 'like', 'to', 'start', 'modeling', 'these', 'counts', 'so', 'that', 'we', 're', 'not', 'just', 'guessing', 'whether', 'something', 'is', 'unusual', 'or', 'not', 'unfortunately', 'i', 've', 'had', 'very', 'little', 'training', 'in', 'time', 'series', 'and', 'most', 'of', 'my', 'exposure', 'has', 'been', 'to', 'models', 'for', 'very', 'continuous', 'data', 'stock', 'prices', 'or', 'very', 'large', 'numbers', 'of', 'counts', 'influenza', 'but', 'we', 'deal', 'with', 'cases', 'per', 'month', 'mean', 'median', 'var', 'which', 'are', 'distributed', 'like', 'this', 'image', 'lost', 'to', 'the', 'mists', 'of', 'time', 'image', 'eaten', 'by', 'a', 'grue', 'i', 've', 'found', 'a', 'few', 'articles', 'that', 'address', 'models', 'like', 'this', 'but', 'i', 'd', 'greatly', 'appreciate', 'hearing', 'suggestions', 'from', 'you', 'both', 'for', 'approaches', 'and', 'for', 'r', 'packages', 'that', 'i', 'could', 'use', 'to', 'implement', 'those', 'approaches', 'edit', 'mbq', 's', 'answer', 'has', 'forced', 'me', 'to', 'think', 'more', 'carefully', 'about', 'what', 'i', 'm', 'asking', 'here', 'i', 'got', 'too', 'hung', 'up', 'on', 'the', 'monthly', 'counts', 'and', 'lost', 'the', 'actual', 'focus', 'of', 'the', 'question', 'what', 'i', 'd', 'like', 'to', 'know', 'is', 'does', 'the', 'fairly', 'visible', 'decline', 'from', 'say', 'onward', 'reflect', 'a', 'downward', 'trend', 'in', 'the', 'overall', 'number', 'of', 'cases', 'it', 'looks', 'to', 'me', 'like', 'the', 'number', 'of', 'cases', 'monthly', 'from', 'reflects', 'a', 'stable', 'process', 'maybe', 'some', 'seasonality', 'but', 'overall', 'stable', 'from', 'through', 'the', 'present', 'it', 'looks', 'like', 'that', 'process', 'is', 'changing', 'the', 'overall', 'number', 'of', 'cases', 'is', 'declining', 'even', 'though', 'the', 'monthly', 'counts', 'might', 'wobble', 'up', 'and', 'down', 'due', 'to', 'randomness', 'and', 'seasonality', 'how', 'can', 'i', 'test', 'if', 'there', 's', 'a', 'real', 'change', 'in', 'the', 'process', 'and', 'if', 'i', 'can', 'identify', 'a', 'decline', 'how', 'could', 'i', 'use', 'that', 'trend', 'and', 'whatever', 'seasonality', 'there', 'might', 'be', 'to', 'estimate', 'the', 'number', 'of', 'cases', 'we', 'might', 'see', 'in', 'the', 'upcoming', 'months', 'whew', 'thanks', 'for', 'bearing', 'with', 'me'], 'tags': 'r,time series'}\n"
     ]
    }
   ],
   "source": [
    "#print preprocessed text\n",
    "print(vars(training_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-QfgorLFIqF"
   },
   "source": [
    "As you can see here, the output is the cleaned text\n",
    "\n",
    "**Note**: *cleaning is done based on the field object defined* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZIK_ogyFmQz"
   },
   "source": [
    "Split the dataset into training and validation now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40EZTlPsBVVA"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = training_data.split(split_ratio=0.8, random_state = random.seed(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0DyjPap1elw"
   },
   "source": [
    "## 3.2 Text Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBOJBsu0F32-"
   },
   "source": [
    "The next step is to build the vocabulary for the text. For this we use *build_vocab* function on field object to construct a vocab object for the field\n",
    "\n",
    "Below are the important parameters for build_vocab:\n",
    "\n",
    "**Parameter**:\n",
    "\n",
    "* **Dataset object**: which is used to specify the data on which vocabulary has to be created\n",
    "\n",
    "* **min_freq**: Ignores the words in vocabulary which has frequency less than or equal to specified one and map it to unknown token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cB5kUf-g9fV8"
   },
   "outputs": [],
   "source": [
    "#preparing the vocabulary for the text\n",
    "TEXT.build_vocab(train_data, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2278,
     "status": "ok",
     "timestamp": 1587057100629,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "t9HPCTmUjvvd",
    "outputId": "d128badd-a19f-4ceb-b986-4110f7e3016b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12484"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No. of unique words\n",
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1985,
     "status": "ok",
     "timestamp": 1587057100629,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "BivXzGMDEUMv",
    "outputId": "c4d7b383-60cd-4d0c-d560-20828811fafa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<unk>', 0),\n",
       " ('<pad>', 1),\n",
       " ('the', 2),\n",
       " ('i', 3),\n",
       " ('to', 4),\n",
       " ('a', 5),\n",
       " ('of', 6),\n",
       " ('is', 7),\n",
       " ('and', 8),\n",
       " ('in', 9)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word index\n",
    "list(TEXT.vocab.stoi.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjvP5RUw97NX"
   },
   "source": [
    "\n",
    "***Note***: Two special tokens known as unknown and padding will be added to the vocabulary by default\n",
    "\n",
    "* **Unknown token** is used to handle Out Of Vocabulary words. By default, the index of unknown token is 0\n",
    "* **Padding token** is used to make input sequences of same length. By default, the padding token is added at index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KH4Hr9bsHAD-"
   },
   "outputs": [],
   "source": [
    "def fetch_text(examples):\n",
    "\n",
    "  text=[]\n",
    "  for example in examples:\n",
    "    query = vars(example)['query']\n",
    "    text.append(query)\n",
    "    \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fP6tbe1YXhcT"
   },
   "outputs": [],
   "source": [
    "train_text = fetch_text(train_data)\n",
    "valid_text = fetch_text(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCmD_tscB8Tc"
   },
   "outputs": [],
   "source": [
    "def convert2seq(text):\n",
    "  \n",
    "  #padding\n",
    "  text = TEXT.pad(text)\n",
    "  \n",
    "  #converting to numbers\n",
    "  text = TEXT.numericalize(text)\n",
    "  \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gy0jLpHk-gEy"
   },
   "outputs": [],
   "source": [
    "X_train = convert2seq(train_text)\n",
    "X_valid = convert2seq(valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2837,
     "status": "ok",
     "timestamp": 1587057105005,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "D9-AU-oUj9Uq",
    "outputId": "fbfb82c4-78f5-4ec1-e082-7d01976b7560"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3,    17,     2,    15,    98,    33,    86,     3,   250,     4,\n",
       "          520,     2,    94,    40,    21,    50,   193,    74,   294,   635,\n",
       "           65,     9, 12272,     3,    17,   266,   283,    78,    26,  2481,\n",
       "         3593,    33,    13,     7,  1877,    12,   103,    21,  2365,  1163,\n",
       "           15,   276,   841,     6,    62,  9866,   460,     0,   460,     0,\n",
       "          460,     0,   460,     0,   460,     0,   927,  4131,   460, 12272,\n",
       "          460,     0,   460,     0,   460,     0,   460,     0,  8616,   286,\n",
       "          286,   286,   286,   286,   286,     0,   460, 10036,   460,   329,\n",
       "            7,    65,  1163,   286,    24,    15,   117,    32,  1374,    66,\n",
       "           65,    69,    70,   598,   681,   104,   681,  1163, 10036,     0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2255,
     "status": "ok",
     "timestamp": 1587057105006,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "5_kAvrkbP6KU",
    "outputId": "f71f62db-d72d-417c-fb72-676a736f9e79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8885, 100]), torch.Size([2221, 100]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vl_S6Ql2fwjh"
   },
   "outputs": [],
   "source": [
    "def fetch_tags(data):\n",
    "  tags=[]\n",
    "  for example in data.examples:\n",
    "    tags.append(vars(example)['tags'])\n",
    "  return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2L4V-Zdwf1FT"
   },
   "outputs": [],
   "source": [
    "train_tags = fetch_tags(train_data)\n",
    "valid_tags = fetch_tags(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1827,
     "status": "ok",
     "timestamp": 1587057105839,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "RwcyVXZE_1MW",
    "outputId": "60d38cb0-f96c-47a7-fe55-6eeeff2b3286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r,logistic',\n",
       " 'machine learning,classification',\n",
       " 'r,time series',\n",
       " 'r,time series',\n",
       " 'probability,distributions']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmT2dgfvOaGw"
   },
   "outputs": [],
   "source": [
    "#preparing the output labels \n",
    "train_tags_list=[i.split(\",\") for i in train_tags]\n",
    "valid_tags_list=[i.split(\",\") for i in valid_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1586,
     "status": "ok",
     "timestamp": 1587057106559,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "DWwlKMXc_R4S",
    "outputId": "58bcf755-5dd2-4ac8-e330-36839e561dd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb= MultiLabelBinarizer()\n",
    "mlb.fit(train_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1831,
     "status": "ok",
     "timestamp": 1587057107643,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "yc4QfBrX_Ryl",
    "outputId": "f4fa0960-0e75-4b45-d36b-b675deb7046d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['classification', 'distributions', 'hypothesis testing',\n",
       "       'logistic', 'machine learning', 'probability', 'r', 'regression',\n",
       "       'self study', 'time series'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t6bHhjjsO0oA"
   },
   "outputs": [],
   "source": [
    "y_train  = mlb.transform(train_tags_list)\n",
    "y_valid  = mlb.transform(valid_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2851,
     "status": "ok",
     "timestamp": 1587057111647,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "RbhTziq7O0iT",
    "outputId": "2ec1d43f-a6e9-47b9-bc5b-35bc677878d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8885, 10), (2221, 10))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3038,
     "status": "ok",
     "timestamp": 1587057112517,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "R1QdDTe1pKcY",
    "outputId": "138f5745-e16c-4590-d6ec-b3d65241f6de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JS0y7u8MQNxf"
   },
   "outputs": [],
   "source": [
    "y_train = torch.FloatTensor(y_train)\n",
    "y_valid = torch.FloatTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2098,
     "status": "ok",
     "timestamp": 1587057112521,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "PnpswpTgQXuK",
    "outputId": "a842a571-6c9f-458b-a395-d91001139b99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1QO2V5C1q0c"
   },
   "source": [
    "# 4. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwPA0UEV1sdy"
   },
   "source": [
    " ## 4.1 Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AohYMQDYjf5J"
   },
   "source": [
    "Prior to defining a RNN architecture, we will understand the how RNN layer is defined in pytorch, what are the input and output shapes of an RNN layer in PyTorch\n",
    "\n",
    "As you might remember, preprocessed text data is at first passed through Embedding Layer, then the output of this embedding layer is passed through the RNN layer\n",
    "\n",
    "Lets see what the parameters of Embedding Layer are\n",
    "\n",
    "* **num_embeddings**: Actual feature dimensions of input\n",
    "* **embedding_dim**: Number of embedding dimensions; this is set by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-Hu3YNxhx5Z"
   },
   "outputs": [],
   "source": [
    "# define embedding layer\n",
    "emb = Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1522,
     "status": "ok",
     "timestamp": 1587057158809,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "jHL606DglJxs",
    "outputId": "1b0a0f55-c120-4657-fe3c-0765d307c816"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qU_qVYah4sZ"
   },
   "outputs": [],
   "source": [
    "# check sample input\n",
    "sample_embedding = emb(X_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1587057158813,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "qRqMsYe_jJzW",
    "outputId": "255489bf-7212-4a7e-d20a-a0dfe63f56b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 50])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1nf8tfeInil"
   },
   "source": [
    "In Pytorch, you can easily define RNN layers with same hyperparameters using the RNN module of torch.nn \n",
    "\n",
    "Parameters of RNN layer:\n",
    "\n",
    "* **input_size**: Number of inputs to the RNN\n",
    "* **hidden_size**: Number of neurons in RNN layer.\n",
    "* **batch_first**: Set first dimension to batch size\n",
    "* **nonlinearity**: Activation function on RNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GNiEeVSzNqg"
   },
   "outputs": [],
   "source": [
    "#define a rnn\n",
    "rnn = RNN(input_size=50, hidden_size=128, batch_first=True, nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWWNM7emrESx"
   },
   "outputs": [],
   "source": [
    "#pass the input to rnn\n",
    "hidden_states,last_hidden_state = rnn(sample_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1587057162255,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "b2UOiZpIrEOV",
    "outputId": "34d528ff-84e3-4a6a-e206-a8a5239673de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 128])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hidden state of every timestep (Batch, seq_len, no. of hidden neurons)\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1267,
     "status": "ok",
     "timestamp": 1587057163487,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "5X-Sh0Hfsndv",
    "outputId": "16b83da7-f3e5-4d27-f512-eeb9d2b34d09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output shape of last hidden timestep\n",
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2271,
     "status": "ok",
     "timestamp": 1587057164683,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "_CR_ZH74oMKU",
    "outputId": "cc1bf7ed-e377-46ad-a8ac-ff2c3b6b2021"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12800])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping the hidden states\n",
    "reshaped = hidden_states.reshape(hidden_states.size(0),-1)\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ak9rPTehSv0F"
   },
   "outputs": [],
   "source": [
    "# Define Model Architecture\n",
    "\n",
    "# Input\n",
    "# Embedding(embedding_dim=50)\n",
    "# RNN(128)\n",
    "# Linear(128, 'relu')\n",
    "# Linear(10, 'sigmoid')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Constructor\n",
    "        super(Net, self).__init__()   \n",
    "        \n",
    "        self.rnn_layer = nn.Sequential(\n",
    "            \n",
    "            #embedding layer [batch_size,vocab_size]\n",
    "            Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=50),\n",
    "        \n",
    "            #rnn layer [batch_size,100,128]\n",
    "            RNN(input_size=50, hidden_size=128, nonlinearity='relu',batch_first=True)\n",
    "          \n",
    "            )\n",
    "\n",
    "        self.dense_layer = nn.Sequential(\n",
    "            \n",
    "            #[batch_size,100*128]\n",
    "            Linear(12800, 128),\n",
    "\n",
    "            ReLU(),\n",
    "\n",
    "            #[batch_size,128]\n",
    "            Linear(128,10),\n",
    "            \n",
    "            #[batch_size,10]\n",
    "            Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #rnn layer\n",
    "        hidden_states, last_hidden_state = self.rnn_layer(x)\n",
    "\n",
    "        #reshaping\n",
    "        hidden_states = hidden_states.reshape(hidden_states.size(0),-1)\n",
    "\n",
    "        #dense layer\n",
    "        outputs=self.dense_layer(hidden_states)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YJHLpi4Sv5j"
   },
   "outputs": [],
   "source": [
    "#define the model\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2007,
     "status": "ok",
     "timestamp": 1587057167559,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "L4U_4YfbSv_A",
    "outputId": "fd98f284-3970-427b-e1d1-97ff718468e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (rnn_layer): Sequential(\n",
       "    (0): Embedding(12484, 50)\n",
       "    (1): RNN(50, 128, batch_first=True)\n",
       "  )\n",
       "  (dense_layer): Sequential(\n",
       "    (0): Linear(in_features=12800, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model layers\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1602,
     "status": "ok",
     "timestamp": 1587057169459,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "D06A21xv6JaN",
    "outputId": "93573f83-e434-41ed-e00e-b477135152f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4992, 0.5044, 0.4913, 0.5399, 0.5355, 0.4914, 0.5125, 0.5388, 0.4982,\n",
      "         0.5022]])\n"
     ]
    }
   ],
   "source": [
    "#pass an text to the model to understand the output\n",
    "#deactivates autograd\n",
    "with torch.no_grad():\n",
    "  pred = model(X_train[:1])\n",
    "  print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "liHnnKIFjmRj"
   },
   "outputs": [],
   "source": [
    "#define optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = BCELoss()\n",
    "\n",
    "# checking if GPU is available\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()\n",
    "#     criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LleGoa8918PF"
   },
   "source": [
    "## 4.2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_v08HY6Sv84"
   },
   "outputs": [],
   "source": [
    "# define training function\n",
    "def train(X,y,batch_size):\n",
    "\n",
    "  #activate training phase\n",
    "  model.train()\n",
    "  \n",
    "  #initialization\n",
    "  epoch_loss= 0\n",
    "  no_of_batches = 0\n",
    "\n",
    "  #randomly create indices\n",
    "  indices= torch.randperm(len(X))\n",
    "  \n",
    "  #loading in batches\n",
    "  for i in range(0,len(indices),batch_size):\n",
    "    \n",
    "    #indices for a batch\n",
    "    ind = indices[i:i+batch_size]\n",
    "  \n",
    "    #batch  \n",
    "    batch_x=X[ind]\n",
    "    batch_y=y[ind]\n",
    "    \n",
    "    #push to cuda\n",
    "    if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "\n",
    "    #clear gradients\n",
    "    optimizer.zero_grad()\n",
    "          \n",
    "    #forward pass\n",
    "    outputs = model(batch_x)\n",
    "\n",
    "    #converting to a 1 dimensional tensor\n",
    "    outputs = outputs.squeeze()\n",
    "\n",
    "    #calculate loss and accuracy\n",
    "    loss = criterion(outputs, batch_y)\n",
    "    \n",
    "    #Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    #Keep track of the loss and accuracy of a epoch\n",
    "    epoch_loss = epoch_loss + loss.item()\n",
    "\n",
    "    #No. of batches\n",
    "    no_of_batches = no_of_batches+1\n",
    "\n",
    "  return epoch_loss/no_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeCtfkgoSvx8"
   },
   "outputs": [],
   "source": [
    "# define evaluation function\n",
    "def evaluate(X,y,batch_size):\n",
    "\n",
    "  #deactivate training phase\n",
    "  model.eval()\n",
    "\n",
    "  #initialization\n",
    "  epoch_loss = 0\n",
    "  no_of_batches = 0\n",
    "\n",
    "  #randomly create indices\n",
    "  indices= torch.randperm(len(X))\n",
    "\n",
    "  #deactivates autograd\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    #loading in batches\n",
    "    for i in range(0,len(indices),batch_size):\n",
    "      \n",
    "      #indices for a batch\n",
    "      ind = indices[i:i+batch_size]\n",
    "  \n",
    "      #batch  \n",
    "      batch_x= X[ind]\n",
    "      batch_y= y[ind]\n",
    "\n",
    "      #push to cuda\n",
    "      if torch.cuda.is_available():\n",
    "          batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "        \n",
    "      #Forward pass\n",
    "      outputs = model(batch_x)\n",
    "\n",
    "      #converting the output to 1 Dimensional tensor\n",
    "      outputs = outputs.squeeze()\n",
    "\n",
    "      # Calculate loss and accuracy\n",
    "      loss = criterion(outputs, batch_y)\n",
    "      \n",
    "      #keep track of loss and accuracy of an epoch\n",
    "      epoch_loss = epoch_loss + loss.item()\n",
    "\n",
    "      #no. of batches\n",
    "      no_of_batches = no_of_batches + 1\n",
    "\n",
    "    return epoch_loss/no_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73CuJpFUYvDM"
   },
   "outputs": [],
   "source": [
    "# define prediction function\n",
    "def predict(X,batch_size):\n",
    "  \n",
    "  #deactivate training phase\n",
    "  model.eval()\n",
    "\n",
    "  # initialization \n",
    "  predictions = []\n",
    "\n",
    "  # create indices\n",
    "  indices = torch.arange(len(X))\n",
    "\n",
    "  #deactivates autograd\n",
    "  with torch.no_grad():\n",
    "      \n",
    "      for i in range(0, len(X), batch_size):\n",
    "        \n",
    "        #indices for a batch\n",
    "        ind = indices[i:i+batch_size]\n",
    "\n",
    "        # batch\n",
    "        batch_x = X[ind]\n",
    "\n",
    "        #push to cuda\n",
    "        if torch.cuda.is_available():\n",
    "            batch_x = batch_x.cuda()\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        #converting the output to 1 Dimensional tensor\n",
    "        outputs = outputs.squeeze()\n",
    "\n",
    "        # convert to numpy array\n",
    "        prediction = outputs.data.cpu().numpy()\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "  # convert to single numpy array\n",
    "  predictions = np.concatenate(predictions, axis=0)\n",
    "    \n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20094,
     "status": "ok",
     "timestamp": 1587057196073,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "Z5bch29mSve6",
    "outputId": "6a254a0d-360f-4c7d-fc1e-431502210ab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 0 Training loss: 0.2849 \tValidation loss: 0.3399\n",
      "\n",
      "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
      "\n",
      "Epoch : 1 Training loss: 0.1893 \tValidation loss: 0.3628\n",
      "\n",
      "Epoch : 2 Training loss: 0.1019 \tValidation loss: 0.4449\n",
      "\n",
      "Epoch : 3 Training loss: 0.0428 \tValidation loss: 0.5631\n",
      "\n",
      "Epoch : 4 Training loss: 0.0159 \tValidation loss: 0.6773\n",
      "\n",
      "Epoch : 5 Training loss: 0.0057 \tValidation loss: 0.7976\n",
      "\n",
      "Epoch : 6 Training loss: 0.0026 \tValidation loss: 0.8729\n",
      "\n",
      "Epoch : 7 Training loss: 0.0016 \tValidation loss: 0.959\n",
      "\n",
      "Epoch : 8 Training loss: 0.001 \tValidation loss: 1.0365\n",
      "\n",
      "Epoch : 9 Training loss: 0.0009 \tValidation loss: 1.0535\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "batch_size = 32\n",
    "\n",
    "# intialization\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "    train_loss   = train(X_train, y_train, batch_size)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_loss   = evaluate(X_valid, y_valid, batch_size)\n",
    "\n",
    "    print('\\nEpoch :',epoch,\n",
    "          'Training loss:',round(train_loss,4),\n",
    "          '\\tValidation loss:',round(valid_loss,4))\n",
    "\n",
    "    #save the best model\n",
    "    if best_valid_loss >= valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../data/saved_weights.pt') \n",
    "        print(\"\\n----------------------------------------------------Saved best model------------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPD3sYkO2C8k"
   },
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45blbQAZ2M8O"
   },
   "source": [
    "## 5.1 Check Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Do5YNpepVXE3"
   },
   "source": [
    "Load the best model weights and now, the model is ready for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2526,
     "status": "ok",
     "timestamp": 1587057198609,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "Gdj5mP2EYZVz",
    "outputId": "9f1565cc-de29-412a-ded7-c399cd1fecea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path='../data/saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbV0Y8dXYsv2"
   },
   "outputs": [],
   "source": [
    "#predict probabilities\n",
    "y_pred_prob = predict(X_valid, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3309,
     "status": "ok",
     "timestamp": 1587057199405,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "0_K7FERpSvZL",
    "outputId": "62a65ad9-2544-42ed-beab-adedc798abf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00189579, 0.90723705, 0.08528368, 0.01224653, 0.007358  ,\n",
       "       0.3055593 , 0.64462286, 0.28708783, 0.11356665, 0.00915357],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdpKdmTvbEeu"
   },
   "outputs": [],
   "source": [
    "#actual tags\n",
    "y_true = y_valid.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_8v15zo_9D0"
   },
   "source": [
    "The predictions are in terms of probabilities for each of the 10 tags. Hence we need to have a threshold value to convert these probabilities to 0 or 1. Let's specify a set of candidate threshold values. We will select the threshold value that performs the best for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1911,
     "status": "ok",
     "timestamp": 1587057230835,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "eoyr5wlbSmfI",
    "outputId": "5761ee22-9c53-41f2-9157-fc84b3c261c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
      " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
      " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
      " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49]\n"
     ]
    }
   ],
   "source": [
    "#define candidate threshold values\n",
    "threshold  = np.arange(0,0.5,0.01)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G39D2TISVhfO"
   },
   "source": [
    "Let's define a function that takes a threshold value and uses it to convert probabilities into 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvcm8hxPSb3e"
   },
   "outputs": [],
   "source": [
    "# convert probabilities into classes or tags based on a threshold value\n",
    "def classify(y_pred_prob, thresh):\n",
    "  \n",
    "  y_pred = []\n",
    "\n",
    "  for i in y_pred_prob:\n",
    "    temp=[]\n",
    "      \n",
    "    for j in i:\n",
    "      if j>=thresh:\n",
    "        temp.append(1)\n",
    "      else:\n",
    "        temp.append(0)\n",
    "    \n",
    "    y_pred.append(temp)\n",
    "\n",
    "  return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WaH6P-FHhf2Z"
   },
   "source": [
    "We will evaluate the performance of model for each candidate threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gG8OFwSuSb0m"
   },
   "outputs": [],
   "source": [
    "score=[]\n",
    "\n",
    "for thresh in threshold:\n",
    "    \n",
    "    #classes for each threshold\n",
    "    y_pred = classify(y_pred_prob, thresh) \n",
    "\n",
    "    #convert to 1d array\n",
    "    y_pred_1d    =  y_pred.ravel()\n",
    "    y_true_1d    =  y_true.ravel()\n",
    " \n",
    "    score.append(metrics.f1_score(y_true_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3776,
     "status": "ok",
     "timestamp": 1587057251767,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "XBZxqkmSR_8i",
    "outputId": "98d1ef7b-bbe3-498b-cb4d-ff6bb63f9507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34\n"
     ]
    }
   ],
   "source": [
    "# find the optimal threshold\n",
    "opt = threshold[score.index(max(score))]\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eD2l-uNwR7o3"
   },
   "outputs": [],
   "source": [
    "#predictions for optimal threshold\n",
    "y_pred = classify(y_pred_prob, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1875,
     "status": "ok",
     "timestamp": 1587057255400,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "MdHB_HaJR7m2",
    "outputId": "056e383c-e1e1-410e-e002-d6c21ae5fb8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.89      0.90     17478\n",
      "         1.0       0.64      0.68      0.66      4732\n",
      "\n",
      "    accuracy                           0.85     22210\n",
      "   macro avg       0.77      0.79      0.78     22210\n",
      "weighted avg       0.85      0.85      0.85     22210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#converting to 1D\n",
    "y_pred_1d = y_pred.ravel()\n",
    "\n",
    "#Classification report\n",
    "print(metrics.classification_report(y_true_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1656,
     "status": "ok",
     "timestamp": 1587057255403,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "YY-z8S42XTBB",
    "outputId": "d61aa8e6-40e7-415a-ecec-410778c567db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Actual Tags</th>\n",
       "      <th>Predicted Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consider the following model y if g x beta u and y otherwise where u is iid according to some distribution function f i want to recover the distribution f without making too many assumptions that ...</td>\n",
       "      <td>(logistic, regression)</td>\n",
       "      <td>(distributions, r)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am encountering the following problems and i don t really know which model a should pick all model selection criteria indicate that i should take the model with lag after building the var model ...</td>\n",
       "      <td>(hypothesis testing, time series)</td>\n",
       "      <td>(hypothesis testing, r, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basically i m attempting to recreate the results of an example from class in r what i m trying to do is decide whether it s best to use a single regression line for an entire data set or two lines...</td>\n",
       "      <td>(r, regression)</td>\n",
       "      <td>(logistic, r, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in general i standardize my independent variables in regressions in order to properly compare the coefficients this way they have the same units standard deviations however with panel longitudinal...</td>\n",
       "      <td>(r, regression)</td>\n",
       "      <td>(logistic, r, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>let v to be forecasted value for periods through t and v t be its forecasted value at time t we express v t as the sum of two terms its mean at time t and its deviation from the mean at time t eps...</td>\n",
       "      <td>(r, time series)</td>\n",
       "      <td>(time series,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                 Questions  \\\n",
       "0  consider the following model y if g x beta u and y otherwise where u is iid according to some distribution function f i want to recover the distribution f without making too many assumptions that ...   \n",
       "1  i am encountering the following problems and i don t really know which model a should pick all model selection criteria indicate that i should take the model with lag after building the var model ...   \n",
       "2  basically i m attempting to recreate the results of an example from class in r what i m trying to do is decide whether it s best to use a single regression line for an entire data set or two lines...   \n",
       "3  in general i standardize my independent variables in regressions in order to properly compare the coefficients this way they have the same units standard deviations however with panel longitudinal...   \n",
       "4  let v to be forecasted value for periods through t and v t be its forecasted value at time t we express v t as the sum of two terms its mean at time t and its deviation from the mean at time t eps...   \n",
       "\n",
       "                         Actual Tags                       Predicted Tags  \n",
       "0             (logistic, regression)                   (distributions, r)  \n",
       "1  (hypothesis testing, time series)  (hypothesis testing, r, regression)  \n",
       "2                    (r, regression)            (logistic, r, regression)  \n",
       "3                    (r, regression)            (logistic, r, regression)  \n",
       "4                   (r, time series)                       (time series,)  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert back to tags\n",
    "y_pred_label = mlb.inverse_transform(np.array(y_pred))\n",
    "y_true_label = mlb.inverse_transform(np.array(y_true))\n",
    "\n",
    "# get all validation text\n",
    "queries = [\" \".join(i) for i in valid_text]\n",
    "\n",
    "# create a dataframe to show the data and prediction side by side\n",
    "df = pd.DataFrame({'Questions':queries,'Actual Tags':y_true_label,'Predicted Tags':y_pred_label})\n",
    "\n",
    "# print first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ib-fPuHqx2cu"
   },
   "source": [
    "## 5.2 Show Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-xFfFHVdVz5"
   },
   "outputs": [],
   "source": [
    "#raw text\n",
    "text = \"For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2227,
     "status": "ok",
     "timestamp": 1587057263250,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "BzCbTh8_dWJa",
    "outputId": "a7cf7231-61e7-49e7-dd10-a8386eb7cdd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for', 'example', 'in', 'the', 'case']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning text\n",
    "tokens = cleaner(text)\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1644,
     "status": "ok",
     "timestamp": 1587057263253,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "gqoqyJVtfUbP",
    "outputId": "6bcb5bb0-a3a6-4f78-b598-ce3bdd0dbc51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 21)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first argument to the model is no. of samples\n",
    "tokens = np.array(tokens).reshape(-1,len(tokens))\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1587057263256,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "2Tb27oqsdWGH",
    "outputId": "1fd4a3b6-62b7-4bcf-bfa7-7f6a568b37df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  12,  107,    9,    2,  151,    6,   94,   40,    2,  226,   74,    7,\n",
       "            5, 1570,   74,   13, 2927,    4,  960,    2,  373,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting text to integer sequences\n",
    "seq = convert2seq(tokens)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1855,
     "status": "ok",
     "timestamp": 1587057263878,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "c49lZSl4dWDE",
    "outputId": "3966f105-1622-40ce-e0a3-645009c6a538"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1429, 0.0620, 0.0581, 0.8555, 0.2472, 0.1093, 0.1394, 0.7053, 0.0237,\n",
      "         0.0119]])\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "with torch.no_grad():\n",
    "  if torch.cuda.is_available():\n",
    "    seq = seq.cuda()\n",
    "  pred_prob= model(seq)\n",
    "  print(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1668,
     "status": "ok",
     "timestamp": 1587057265245,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "ZeH965i2dVud",
    "outputId": "e0b2f20c-ef5b-4339-a8f5-736cf9383587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify\n",
    "pred = classify(pred_prob,opt)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1587057265249,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "qCf__xiIfFU9",
    "outputId": "1bae0353-22af-4494-cbe1-a75b82ab1d74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('logistic', 'regression')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags  = mlb.inverse_transform(pred)[0]\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nk_3cC8tfFdy"
   },
   "outputs": [],
   "source": [
    "def predict_tags(text):\n",
    "  \n",
    "  tokens = cleaner(text)\n",
    "  \n",
    "  tokens = np.array(tokens).reshape(-1,len(tokens))\n",
    "  \n",
    "  seq = convert2seq(tokens)\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    if torch.cuda.is_available():\n",
    "      seq = seq.cuda()\n",
    "\n",
    "  pred_prob= model(seq)\n",
    "  pred = classify(pred_prob,opt)\n",
    "  \n",
    "  tags  = mlb.inverse_transform(pred)[0]\n",
    "  \n",
    "  return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1628,
     "status": "ok",
     "timestamp": 1587057269938,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "B0Jxz5kmeyEm",
    "outputId": "dfb7a78d-29a8-4013-88db-8b6cfecc7f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\n",
      "Predicted tags: ('logistic', 'regression')\n"
     ]
    }
   ],
   "source": [
    "text = \"For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\"\n",
    "\n",
    "tags = predict_tags(text)\n",
    "print(\"Query: \", text)\n",
    "print(\"Predicted tags:\",tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cN7_48hWIGA"
   },
   "source": [
    "# 6. Model Building for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVOOA6rFq7jc"
   },
   "source": [
    "In Pytorch, you can easily define LSTM layer using the LSTM module of torch.nn \n",
    "\n",
    "Parameters of LSTM layer:\n",
    "\n",
    "* **input_size**: Number of inputs to the LSTM\n",
    "* **hidden_size**: Number of neurons in LSTM layer.\n",
    "* **batch_first**: Set first dimension to batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2023,
     "status": "ok",
     "timestamp": 1587058245660,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "_QazqtX4Fc-c",
    "outputId": "77e93d30-1182-4b4f-bbbc-3f89573c09e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 50])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQdkmPaPrfXK"
   },
   "outputs": [],
   "source": [
    "#define an LSTM\n",
    "lstm_layer = LSTM(input_size=50, hidden_size=128, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZfiG6PQ-6HI"
   },
   "outputs": [],
   "source": [
    "#pass the input to LSTM\n",
    "hidden_states, (last_hidden_state,last_cell_state) = lstm_layer(sample_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2252,
     "status": "ok",
     "timestamp": 1587058315091,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "_iipOXzw_Gss",
    "outputId": "855d7ae8-a92e-488d-e184-ed7254515459"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 128])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hidden state of every timestep (Batch, seq_len, no. of hidden neurons)\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1347,
     "status": "ok",
     "timestamp": 1587058320512,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "drJDL9gB_Iq7",
    "outputId": "78d0f9a6-62b2-4872-aafd-a83eb524706d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output shape of last hidden timestep\n",
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1950,
     "status": "ok",
     "timestamp": 1587058336148,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "0WB6t5Dl_aoI",
    "outputId": "4beda0f9-7f37-4645-e5cc-8f854e78fb93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output shape of last cell state\n",
    "last_cell_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1587058424715,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "zO_vOTns_KNW",
    "outputId": "10cd6355-f9ce-4ca6-fc0d-6e7941330bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12800])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping the hidden states\n",
    "reshaped = hidden_states.reshape(hidden_states.size(0),-1)\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pOsmRHSQYuN"
   },
   "outputs": [],
   "source": [
    "# Define Model Architecture\n",
    "\n",
    "# Input\n",
    "# Embedding(embedding_dim=100)\n",
    "# LSTM(128)\n",
    "# Linear(128, 'relu')\n",
    "# Linear(10, 'sigmoid')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    #Constructor\n",
    "    def __init__(self):\n",
    "\n",
    "        #Constructor\n",
    "        super(Net, self).__init__()   \n",
    "  \n",
    "        #rnn block\n",
    "        self.lstm_layer = Sequential(\n",
    "            \n",
    "            #embedding layer\n",
    "            Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=100),\n",
    "        \n",
    "            #lstm layer\n",
    "            LSTM(input_size=100, hidden_size=128, batch_first=True)\n",
    "          \n",
    "            )\n",
    "\n",
    "        #dense block\n",
    "        self.dense_layer = Sequential(\n",
    "            \n",
    "            Linear(12800,128),\n",
    "\n",
    "            ReLU(),\n",
    "\n",
    "            Linear(128,10),\n",
    "            \n",
    "            Sigmoid()\n",
    "\n",
    "        )\n",
    "    \n",
    "    #forward pass\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #rnn layer\n",
    "        hidden_states, (last_hidden_state,last_cell_state) = self.lstm_layer(x)\n",
    "\n",
    "        #flattening\n",
    "        hidden_states = hidden_states.reshape(hidden_states.size(0),-1)\n",
    "        \n",
    "        #dense layer\n",
    "        outputs=self.dense_layer(hidden_states)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUU13yvgQY1G"
   },
   "outputs": [],
   "source": [
    "#define the model\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1460,
     "status": "ok",
     "timestamp": 1587058583156,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "-RBtZlDJuu-1",
    "outputId": "b22b08b5-1d36-4784-95fd-adea88063f5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lstm_layer): Sequential(\n",
       "    (0): Embedding(12484, 100)\n",
       "    (1): LSTM(100, 128, batch_first=True)\n",
       "  )\n",
       "  (dense_layer): Sequential(\n",
       "    (0): Linear(in_features=12800, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#layers of the model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1372,
     "status": "ok",
     "timestamp": 1587058617840,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "4q01g37DbW1n",
    "outputId": "4b76b2a2-fe35-4d7a-d7c1-41ef40ef5d1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5003, 0.4859, 0.4784, 0.5243, 0.4785, 0.4875, 0.5137, 0.4805, 0.5118,\n",
      "         0.5096]])\n"
     ]
    }
   ],
   "source": [
    "#pass an text to the model to understand the output\n",
    "\n",
    "#deactivates autograd\n",
    "with torch.no_grad():\n",
    "  pred = model(X_train[:1])\n",
    "  print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDxhclMZvUHT"
   },
   "outputs": [],
   "source": [
    "#define optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = BCELoss()\n",
    "\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21997,
     "status": "ok",
     "timestamp": 1587058672041,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "JlSsG3LQvUNl",
    "outputId": "c7897532-d1f6-48c0-eb34-b9e5c085ac0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 0 Training loss: 0.301 \tValidation loss: 0.3236\n",
      "\n",
      "----------------------------------------------------Saved best model------------------------------------------------------------------\n",
      "\n",
      "Epoch : 1 Training loss: 0.1788 \tValidation loss: 0.3545\n",
      "\n",
      "Epoch : 2 Training loss: 0.0698 \tValidation loss: 0.4603\n",
      "\n",
      "Epoch : 3 Training loss: 0.0188 \tValidation loss: 0.5978\n",
      "\n",
      "Epoch : 4 Training loss: 0.0052 \tValidation loss: 0.7142\n",
      "\n",
      "Epoch : 5 Training loss: 0.0022 \tValidation loss: 0.8119\n",
      "\n",
      "Epoch : 6 Training loss: 0.0011 \tValidation loss: 0.8952\n",
      "\n",
      "Epoch : 7 Training loss: 0.0008 \tValidation loss: 0.9946\n",
      "\n",
      "Epoch : 8 Training loss: 0.0006 \tValidation loss: 1.031\n",
      "\n",
      "Epoch : 9 Training loss: 0.0003 \tValidation loss: 1.104\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "batch_size = 32\n",
    "\n",
    "# intialization\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    #train the model\n",
    "    train_loss   = train(X_train, y_train, batch_size)\n",
    "    \n",
    "    #evaluate the model\n",
    "    valid_loss   = evaluate(X_valid, y_valid, batch_size)\n",
    "\n",
    "    print('\\nEpoch :',epoch,\n",
    "          'Training loss:',round(train_loss,4),\n",
    "          '\\tValidation loss:',round(valid_loss,4))\n",
    "\n",
    "    #save the best model \n",
    "    if best_valid_loss >= valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../datasaved_weights_lstm.pt') \n",
    "        print(\"\\n----------------------------------------------------Saved best model------------------------------------------------------------------\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWU2ZDir2q0j"
   },
   "source": [
    "# 7. Model Evaluation for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYLfWSpqvniv"
   },
   "source": [
    "Load the best model weights and now, the model is ready for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1701,
     "status": "ok",
     "timestamp": 1587058715670,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "K_jPYFKzvUUq",
    "outputId": "825760d5-ec81-456a-b26d-77b76ea8ef36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path='saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCLWSfuXQYy9"
   },
   "outputs": [],
   "source": [
    "#predict probabilities\n",
    "y_pred_prob = predict(X_valid, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1911,
     "status": "ok",
     "timestamp": 1587058722214,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "srL5tr77hAfP",
    "outputId": "186f8c3f-71a1-4314-f46b-02c9a33eed4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00569856, 0.04902776, 0.09942988, 0.02161415, 0.09411245,\n",
       "       0.04785799, 0.19031535, 0.76762176, 0.50701326, 0.05482058],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0d3ubp2hAdA"
   },
   "outputs": [],
   "source": [
    "score=[]\n",
    "\n",
    "for thresh in threshold:\n",
    "    \n",
    "    #classes for each threshold\n",
    "    y_pred = classify(y_pred_prob, thresh) \n",
    "\n",
    "    #convert to 1d array\n",
    "    y_pred_1d    =  y_pred.ravel()\n",
    "    y_true_1d    =  y_true.ravel()\n",
    " \n",
    "    score.append(metrics.f1_score(y_true_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2873,
     "status": "ok",
     "timestamp": 1587058745176,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "FxFk7Gg3hAa8",
    "outputId": "370d1ff4-f36a-4c07-febc-fdf9e62be54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33\n"
     ]
    }
   ],
   "source": [
    "# find the optimal threshold\n",
    "opt = threshold[score.index(max(score))]\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_E8xaA0BhAXy"
   },
   "outputs": [],
   "source": [
    "#predictions for optimal threshold\n",
    "y_pred = classify(y_pred_prob, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1587058766872,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "tyr-2stWhAVB",
    "outputId": "32298b56-5e97-4585-ed7b-174fa151641e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.91      0.91     17478\n",
      "         1.0       0.67      0.70      0.68      4732\n",
      "\n",
      "    accuracy                           0.86     22210\n",
      "   macro avg       0.79      0.80      0.80     22210\n",
      "weighted avg       0.86      0.86      0.86     22210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#converting to 1D\n",
    "y_pred_1d = y_pred.ravel()\n",
    "\n",
    "#Classification report\n",
    "print(metrics.classification_report(y_true_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHxsCTdNhAR2"
   },
   "outputs": [],
   "source": [
    "y_pred_label = mlb.inverse_transform(np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hAUPQFNhAP-"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'comment':queries,'actual':y_true_label,'predictions':y_pred_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1587058807877,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "Fd_7LeiDhAM6",
    "outputId": "eb382699-1ead-4849-c779-b06bc56b5913"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>actual</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consider the following model y if g x beta u and y otherwise where u is iid according to some distribution function f i want to recover the distribution f without making too many assumptions that ...</td>\n",
       "      <td>(logistic, regression)</td>\n",
       "      <td>(regression, self study)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am encountering the following problems and i don t really know which model a should pick all model selection criteria indicate that i should take the model with lag after building the var model ...</td>\n",
       "      <td>(hypothesis testing, time series)</td>\n",
       "      <td>(hypothesis testing, r, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>basically i m attempting to recreate the results of an example from class in r what i m trying to do is decide whether it s best to use a single regression line for an entire data set or two lines...</td>\n",
       "      <td>(r, regression)</td>\n",
       "      <td>(r, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in general i standardize my independent variables in regressions in order to properly compare the coefficients this way they have the same units standard deviations however with panel longitudinal...</td>\n",
       "      <td>(r, regression)</td>\n",
       "      <td>(r, regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>let v to be forecasted value for periods through t and v t be its forecasted value at time t we express v t as the sum of two terms its mean at time t and its deviation from the mean at time t eps...</td>\n",
       "      <td>(r, time series)</td>\n",
       "      <td>(time series,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                   comment  ...                          predictions\n",
       "0  consider the following model y if g x beta u and y otherwise where u is iid according to some distribution function f i want to recover the distribution f without making too many assumptions that ...  ...             (regression, self study)\n",
       "1  i am encountering the following problems and i don t really know which model a should pick all model selection criteria indicate that i should take the model with lag after building the var model ...  ...  (hypothesis testing, r, regression)\n",
       "2  basically i m attempting to recreate the results of an example from class in r what i m trying to do is decide whether it s best to use a single regression line for an entire data set or two lines...  ...                      (r, regression)\n",
       "3  in general i standardize my independent variables in regressions in order to properly compare the coefficients this way they have the same units standard deviations however with panel longitudinal...  ...                      (r, regression)\n",
       "4  let v to be forecasted value for periods through t and v t be its forecasted value at time t we express v t as the sum of two terms its mean at time t and its deviation from the mean at time t eps...  ...                       (time series,)\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1770,
     "status": "ok",
     "timestamp": 1587058826494,
     "user": {
      "displayName": "Aishwarya Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgeJwfn4BdBDCAplWi_kdtB9FRssOpXO7T_aMgg=s64",
      "userId": "01105858832371513140"
     },
     "user_tz": -330
    },
    "id": "x4kI46Z4hAJ8",
    "outputId": "1140576f-2310-4d66-c49b-65dc4d07fb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\n",
      "Predicted tags: ('logistic', 'r', 'regression')\n"
     ]
    }
   ],
   "source": [
    "text = \"For example, in the case of logistic regression, the learning function is a Sigmoid function that tries to separate the 2 classes\"\n",
    "\n",
    "tags = predict_tags(text)\n",
    "print(\"Query: \",text)\n",
    "print(\"Predicted tags:\",tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EASR-WztmqMO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "f1QO2V5C1q0c",
    "iPD3sYkO2C8k",
    "8cN7_48hWIGA",
    "qWU2ZDir2q0j"
   ],
   "name": "9. RNN and its variants in PyTorch.ipynb",
   "provenance": [
    {
     "file_id": "1BtDbWw0mtwboStwS9sEf5SdSlFC111Tc",
     "timestamp": 1586784697756
    },
    {
     "file_id": "19Hzy67tbSlGuOvaOoQSMgqsepFvCisNz",
     "timestamp": 1586772281540
    },
    {
     "file_id": "15rk8Z8BW1EIXaEZwdEPsYx9GTDRjeXec",
     "timestamp": 1586687933683
    }
   ]
  },
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
